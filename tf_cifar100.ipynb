{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(x, y), (x2, y2) = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.legacy.Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 [==============================] - 112s 282ms/step - loss: 4.6608 - sparse_categorical_accuracy: 0.0927\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - 94s 241ms/step - loss: 3.9634 - sparse_categorical_accuracy: 0.1547\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - 87s 222ms/step - loss: 3.6317 - sparse_categorical_accuracy: 0.1886\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - 90s 231ms/step - loss: 3.4222 - sparse_categorical_accuracy: 0.2201\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - 88s 225ms/step - loss: 3.3060 - sparse_categorical_accuracy: 0.2414\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - 92s 234ms/step - loss: 3.1960 - sparse_categorical_accuracy: 0.2630\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - 103s 264ms/step - loss: 3.1256 - sparse_categorical_accuracy: 0.2807\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - 93s 237ms/step - loss: 3.0601 - sparse_categorical_accuracy: 0.2963\n",
      "Epoch 9/15\n",
      "391/391 [==============================] - 100s 257ms/step - loss: 3.0001 - sparse_categorical_accuracy: 0.3110\n",
      "Epoch 10/15\n",
      "391/391 [==============================] - 116s 298ms/step - loss: 2.9482 - sparse_categorical_accuracy: 0.3216\n",
      "Epoch 11/15\n",
      "391/391 [==============================] - 105s 270ms/step - loss: 2.9070 - sparse_categorical_accuracy: 0.3324\n",
      "Epoch 12/15\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.8676 - sparse_categorical_accuracy: 0.3392\n",
      "Epoch 13/15\n",
      "391/391 [==============================] - 104s 267ms/step - loss: 2.8287 - sparse_categorical_accuracy: 0.3475\n",
      "Epoch 14/15\n",
      "391/391 [==============================] - 100s 256ms/step - loss: 2.7888 - sparse_categorical_accuracy: 0.3563\n",
      "Epoch 15/15\n",
      "391/391 [==============================] - 112s 287ms/step - loss: 2.7747 - sparse_categorical_accuracy: 0.3600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17d65f8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 2.7482 - sparse_categorical_accuracy: 0.3713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7482357025146484, 0.37130001187324524]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n",
      "lamp mountain\n",
      "palm_tree forest\n",
      "spider seal\n",
      "mushroom mushroom\n",
      "sea sea\n",
      "bee tulip\n",
      "kangaroo camel\n",
      "butterfly butterfly\n",
      "sea cloud\n",
      "pear apple\n",
      "television sea\n",
      "skunk skunk\n",
      "pickup_truck streetcar\n",
      "rocket rocket\n",
      "chair lamp\n",
      "lion lion\n",
      "bottle tulip\n",
      "wolf wolf\n",
      "rose rose\n",
      "orange orange\n",
      "rose rose\n",
      "mountain mountain\n",
      "boy skunk\n",
      "skyscraper dinosaur\n",
      "chimpanzee chimpanzee\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "classes = ['apple',\n",
    " 'aquarium_fish',\n",
    " 'baby',\n",
    " 'bear',\n",
    " 'beaver',\n",
    " 'bed',\n",
    " 'bee',\n",
    " 'beetle',\n",
    " 'bicycle',\n",
    " 'bottle',\n",
    " 'bowl',\n",
    " 'boy',\n",
    " 'bridge',\n",
    " 'bus',\n",
    " 'butterfly',\n",
    " 'camel',\n",
    " 'can',\n",
    " 'castle',\n",
    " 'caterpillar',\n",
    " 'cattle',\n",
    " 'chair',\n",
    " 'chimpanzee',\n",
    " 'clock',\n",
    " 'cloud',\n",
    " 'cockroach',\n",
    " 'couch',\n",
    " 'crab',\n",
    " 'crocodile',\n",
    " 'cup',\n",
    " 'dinosaur',\n",
    " 'dolphin',\n",
    " 'elephant',\n",
    " 'flatfish',\n",
    " 'forest',\n",
    " 'fox',\n",
    " 'girl',\n",
    " 'hamster',\n",
    " 'house',\n",
    " 'kangaroo',\n",
    " 'keyboard',\n",
    " 'lamp',\n",
    " 'lawn_mower',\n",
    " 'leopard',\n",
    " 'lion',\n",
    " 'lizard',\n",
    " 'lobster',\n",
    " 'man',\n",
    " 'maple_tree',\n",
    " 'motorcycle',\n",
    " 'mountain',\n",
    " 'mouse',\n",
    " 'mushroom',\n",
    " 'oak_tree',\n",
    " 'orange',\n",
    " 'orchid',\n",
    " 'otter',\n",
    " 'palm_tree',\n",
    " 'pear',\n",
    " 'pickup_truck',\n",
    " 'pine_tree',\n",
    " 'plain',\n",
    " 'plate',\n",
    " 'poppy',\n",
    " 'porcupine',\n",
    " 'possum',\n",
    " 'rabbit',\n",
    " 'raccoon',\n",
    " 'ray',\n",
    " 'road',\n",
    " 'rocket',\n",
    " 'rose',\n",
    " 'sea',\n",
    " 'seal',\n",
    " 'shark',\n",
    " 'shrew',\n",
    " 'skunk',\n",
    " 'skyscraper',\n",
    " 'snail',\n",
    " 'snake',\n",
    " 'spider',\n",
    " 'squirrel',\n",
    " 'streetcar',\n",
    " 'sunflower',\n",
    " 'sweet_pepper',\n",
    " 'table',\n",
    " 'tank',\n",
    " 'telephone',\n",
    " 'television',\n",
    " 'tiger',\n",
    " 'tractor',\n",
    " 'train',\n",
    " 'trout',\n",
    " 'tulip',\n",
    " 'turtle',\n",
    " 'wardrobe',\n",
    " 'whale',\n",
    " 'willow_tree',\n",
    " 'wolf',\n",
    " 'woman',\n",
    " 'worm']\n",
    "\n",
    "for i, e in enumerate(model.predict(x2[:25])):\n",
    "    print(classes[np.argmax(e)], classes[y2[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'butterfly'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "def resize_image(image, target_size=(32, 32)):\n",
    "    return tf.image.resize(image, target_size)\n",
    "\n",
    "def predict_single_image(image_path):\n",
    "    img = np.array(PIL.Image.open(image_path))\n",
    "    class_probabilities = model.predict(np.array([resize_image(img)]))\n",
    "    return classes[np.argmax(class_probabilities)]\n",
    "\n",
    "\n",
    "predict_single_image('download.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mojo-CiaEp4gG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
